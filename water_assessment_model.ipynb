{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"-KSPG3ZFyqqF","executionInfo":{"status":"ok","timestamp":1733643307884,"user_tz":420,"elapsed":7543,"user":{"displayName":"DS","userId":"14737592924309117665"}}},"outputs":[],"source":["#Step1: Importing necessary libraries\n","import pandas as pd\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","source":["#Step2: Mount google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"UsywB_cs21xF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733643329251,"user_tz":420,"elapsed":21419,"user":{"displayName":"DS","userId":"14737592924309117665"}},"outputId":"772c3f39-5967-4ead-9796-41762389539d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#Step3: Data Preprocessing and Cleaning for Turbidity Dataset.\n","\n","import pandas as pd\n","# Load the dataset\n","data = pd.read_csv('/content/drive/MyDrive/Engg680_Project2024_Group15/dataset/Turbidity_cleaned data.csv')\n","# Clean the 'Sample Date' column by stripping spaces\n","data['Sample Date'] = data['Sample Date'].str.strip()\n","# Convert the 'Sample Date' column to datetime\n","# Adjust the format if you know it (e.g., '%m/%d/%Y' for MM/DD/YYYY)\n","data['Sample Date'] = pd.to_datetime(data['Sample Date'], errors='coerce')\n","# Check for invalid dates\n","if data['Sample Date'].isna().any():\n","  print(\"Warning: Some dates could not be parsed. Check these rows:\")\n","  print(data[data['Sample Date'].isna()])\n","# Drop rows with invalid dates\n","data.dropna(subset=['Sample Date'], inplace=True)\n","# Set 'Sample Date' as the index\n","data.set_index('Sample Date', inplace=True)"],"metadata":{"id":"Ttr6ldSXCPRO","executionInfo":{"status":"ok","timestamp":1733643330074,"user_tz":420,"elapsed":831,"user":{"displayName":"DS","userId":"14737592924309117665"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#Step4: Extracting and Cleaning the Numeric Column\n","data = data['Numeric Result'].dropna()"],"metadata":{"id":"NW23VQ2yDC4h","executionInfo":{"status":"ok","timestamp":1733643330076,"user_tz":420,"elapsed":31,"user":{"displayName":"DS","userId":"14737592924309117665"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Step 5: Generating Lagged Features for Supervised Learning\n","\n","def create_lagged_features(data, n_lags=12):\n","    df = pd.DataFrame(data)\n","    for lag in range(1, n_lags + 1):\n","        df[f'lag_{lag}'] = df['Numeric Result'].shift(lag)\n","    df.dropna(inplace=True)\n","    return df\n","\n","n_lags = 12\n","data_lagged = create_lagged_features(data, n_lags)"],"metadata":{"id":"dBNlAbllJDLz","executionInfo":{"status":"ok","timestamp":1733643624704,"user_tz":420,"elapsed":141,"user":{"displayName":"DS","userId":"14737592924309117665"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Step6: Data Splitting and Training a Random Forest Model\n","# Split the data into features and target\n","X = data_lagged.drop(columns='Numeric Result')\n","y = data_lagged['Numeric Result']\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n","# Train a Random Forest model\n","rf = RandomForestRegressor(n_estimators=100, random_state=42)\n","rf.fit(X_train, y_train)"],"metadata":{"id":"6UFgxN3vMCfX","executionInfo":{"status":"aborted","timestamp":1733643330079,"user_tz":420,"elapsed":23,"user":{"displayName":"DS","userId":"14737592924309117665"}}},"execution_count":null,"outputs":[]}]}