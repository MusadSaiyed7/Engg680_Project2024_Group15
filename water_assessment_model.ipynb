{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"-KSPG3ZFyqqF","executionInfo":{"status":"ok","timestamp":1733642209248,"user_tz":420,"elapsed":3553,"user":{"displayName":"venkata prasanna kumar Gurugubelli","userId":"14853828695125189406"}}},"outputs":[],"source":["#Step1: Importing necessary libraries\n","import pandas as pd\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","source":["#Step2: Mount google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"UsywB_cs21xF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733642227178,"user_tz":420,"elapsed":16088,"user":{"displayName":"venkata prasanna kumar Gurugubelli","userId":"14853828695125189406"}},"outputId":"a22840a0-ae77-4555-ab41-a44665255a7a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#Step3: Data Preprocessing and Cleaning for Turbidity Dataset.\n","\n","import pandas as pd\n","# Load the dataset\n","data = pd.read_csv('/content/drive/MyDrive/Engg680_Project2024_Group15/dataset/Turbidity_cleaned data.csv')\n","# Clean the 'Sample Date' column by stripping spaces\n","data['Sample Date'] = data['Sample Date'].str.strip()\n","# Convert the 'Sample Date' column to datetime\n","# Adjust the format if you know it (e.g., '%m/%d/%Y' for MM/DD/YYYY)\n","data['Sample Date'] = pd.to_datetime(data['Sample Date'], errors='coerce')\n","# Check for invalid dates\n","if data['Sample Date'].isna().any():\n","  print(\"Warning: Some dates could not be parsed. Check these rows:\")\n","  print(data[data['Sample Date'].isna()])\n","# Drop rows with invalid dates\n","data.dropna(subset=['Sample Date'], inplace=True)\n","# Set 'Sample Date' as the index\n","data.set_index('Sample Date', inplace=True)"],"metadata":{"id":"Ttr6ldSXCPRO","executionInfo":{"status":"ok","timestamp":1733642234773,"user_tz":420,"elapsed":802,"user":{"displayName":"venkata prasanna kumar Gurugubelli","userId":"14853828695125189406"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#Step4: Extracting and Cleaning the Numeric Column\n","data = data['Numeric Result'].dropna()"],"metadata":{"id":"NW23VQ2yDC4h","executionInfo":{"status":"ok","timestamp":1733642242863,"user_tz":420,"elapsed":162,"user":{"displayName":"venkata prasanna kumar Gurugubelli","userId":"14853828695125189406"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["Step5: Generating Lagged Features for Supervised Learning\n","# Create lagged features for supervised learning\n","def create_lagged_features(data, n_lags=12):\n","df = pd.DataFrame(data)\n","for lag in range(1, n_lags + 1):\n","df[f'lag_{lag}'] = df['Numeric Result'].shift(lag)\n","df.dropna(inplace=True)\n","return df\n","n_lags = 12\n","data_lagged = create_lagged_features(data, n_lags)"],"metadata":{"id":"dBNlAbllJDLz"},"execution_count":null,"outputs":[]}]}